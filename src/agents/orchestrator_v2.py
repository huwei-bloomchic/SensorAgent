"""
Agentç¼–æ’å™¨ V2 - åŒå±‚æ¶æ„
ä¸»è¦çš„æ™ºèƒ½ä»£ç†ï¼Œåè°ƒä¸Šå±‚åˆ†æAgentå’Œä¸‹å±‚SQLæ‰§è¡ŒAgent
"""
from typing import Optional, Dict, Any
from loguru import logger
from datetime import datetime
import json
import re

from config.settings import get_settings
from src.sensors.client import SensorsClient
from src.agents.analyst_agent import AnalystAgent
from src.agents.engineer_agent import EngineerAgent


class SensorsAnalyticsAgentV2:
    """
    ç¥ç­–æ•°æ®åˆ†ææ™ºèƒ½åŠ©æ‰‹ V2 - åŒå±‚æ¶æ„

    æ¶æ„:
    - ä¸Šå±‚: AnalystAgent (åˆ†æè§„åˆ’) - æ‡‚ä¸šåŠ¡ï¼Œä¸æ‡‚SQL
    - ä¸‹å±‚: EngineerAgent (SQLæ‰§è¡Œ) - æ‡‚SQLï¼Œä¸æ‡‚ä¸šåŠ¡å½’å› 
    - åè°ƒ: Orchestrator - è´Ÿè´£ä¸Šä¸‹å±‚é€šä¿¡å’Œæµç¨‹æ§åˆ¶

    åŠŸèƒ½:
    - ç†è§£ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢
    - ä¸Šå±‚Agentç”Ÿæˆåˆ†æè®¡åˆ’
    - ä¸‹å±‚Agentæ‰§è¡ŒSQLæŸ¥è¯¢
    - ä¸Šå±‚Agentç»¼åˆç»“æœå¹¶ç”Ÿæˆæ´å¯Ÿ
    """

    def __init__(
        self,
        sensors_client: Optional[SensorsClient] = None,
        analyst_model_name: Optional[str] = None,
        engineer_model_name: Optional[str] = None,
        api_key: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–åŒå±‚Agentæ¶æ„

        Args:
            sensors_client: ç¥ç­–APIå®¢æˆ·ç«¯(å¯é€‰)
            analyst_model_name: ä¸Šå±‚Agentæ¨¡å‹åç§°(å¯é€‰)
            engineer_model_name: ä¸‹å±‚Agentæ¨¡å‹åç§°(å¯é€‰)
            api_key: APIå¯†é’¥(å¯é€‰)
        """
        self.settings = get_settings()

        # åˆå§‹åŒ–ç¥ç­–å®¢æˆ·ç«¯
        if sensors_client is None:
            sensors_client = self._create_sensors_client()
        self.sensors_client = sensors_client

        # åˆå§‹åŒ–ä¸Šå±‚åˆ†æAgent
        logger.info("åˆå§‹åŒ–ä¸Šå±‚åˆ†æAgent (AnalystAgent)...")
        self.analyst_agent = AnalystAgent(
            model_name=analyst_model_name or self.settings.LITELLM_MODEL,
            api_key=api_key or self.settings.LITELLM_API_KEY
        )

        # åˆå§‹åŒ–ä¸‹å±‚SQLæ‰§è¡ŒAgent
        logger.info("åˆå§‹åŒ–ä¸‹å±‚SQLæ‰§è¡ŒAgent (EngineerAgent)...")
        self.engineer_agent = EngineerAgent(
            sensors_client=sensors_client,
            model_name=engineer_model_name or self.settings.LITELLM_MODEL,
            api_key=api_key or self.settings.LITELLM_API_KEY
        )

        logger.info("=" * 80)
        logger.info("åŒå±‚Agentæ¶æ„åˆå§‹åŒ–å®Œæˆ")
        logger.info("  â”œâ”€ ä¸Šå±‚: AnalystAgent (ä¸šåŠ¡åˆ†æ)")
        logger.info("  â””â”€ ä¸‹å±‚: EngineerAgent (SQLæ‰§è¡Œ)")
        logger.info("=" * 80)

    def _create_sensors_client(self) -> SensorsClient:
        """åˆ›å»ºç¥ç­–APIå®¢æˆ·ç«¯"""
        logger.info("åˆ›å»ºç¥ç­–APIå®¢æˆ·ç«¯...")

        client = SensorsClient(
            api_url=self.settings.SENSORS_API_URL,
            project=self.settings.SENSORS_PROJECT,
            api_key=self.settings.SENSORS_API_KEY,
            timeout=self.settings.REQUEST_TIMEOUT,
            max_retries=self.settings.MAX_RETRIES
        )

        return client

    def query(self, user_input: str, enable_progressive_analysis: bool = True) -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - æ¸è¿›å¼åŒå±‚æ¶æ„åä½œæµç¨‹

        æ¸è¿›å¼åˆ†ææµç¨‹:
        1. ä¸Šå±‚Agentç”Ÿæˆåˆæ­¥æŸ¥è¯¢æŒ‡ä»¤
        2. ä¸‹å±‚Agentæ‰§è¡Œåˆæ­¥æŸ¥è¯¢
        3. ä¸Šå±‚Agentè¯„ä¼°ç»“æœï¼Œå†³å®šæ˜¯å¦éœ€è¦ä¸‹é’»
        4. å¦‚æœéœ€è¦ï¼Œç”Ÿæˆä¸‹é’»æŒ‡ä»¤å¹¶æ‰§è¡Œ
        5. ç»¼åˆæ‰€æœ‰ç»“æœï¼Œç”Ÿæˆæ´å¯Ÿ

        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            enable_progressive_analysis: æ˜¯å¦å¯ç”¨æ¸è¿›å¼åˆ†æ (é»˜è®¤True)

        Returns:
            åˆ†æç»“æœå’Œæ´å¯Ÿ
        """
        logger.info("=" * 80)
        logger.info(f"[Orchestrator V2] å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_input}")
        logger.info(f"[æ¸è¿›å¼åˆ†æ] {'å¯ç”¨' if enable_progressive_analysis else 'ç¦ç”¨'}")
        logger.info("=" * 80)

        try:
            # ============ é˜¶æ®µ1: åˆæ­¥åˆ†æå’Œè§„åˆ’ ============
            logger.info("\n" + "=" * 80)
            logger.info("ã€é˜¶æ®µ1ã€‘ä¸Šå±‚åˆ†æAgent - ç”Ÿæˆåˆæ­¥æŸ¥è¯¢")
            logger.info("=" * 80)

            analysis_result = self.analyst_agent.analyze(user_input, stage="initial")
            analysis_plan = analysis_result.get("analysis_plan", "")

            logger.info(f"[åˆæ­¥åˆ†æè®¡åˆ’]\n{analysis_plan}")

            # è§£æåˆ†æè®¡åˆ’ï¼Œæå–åˆæ­¥æŒ‡ä»¤
            initial_instructions = self._parse_instructions(analysis_plan)

            if not initial_instructions:
                logger.warning("æœªèƒ½ä»åˆ†æè®¡åˆ’ä¸­æå–åˆ°å…·ä½“æŒ‡ä»¤ï¼Œä½¿ç”¨é»˜è®¤æŒ‡ä»¤")
                initial_instructions = [{
                    "task": user_input,
                    "time_range": "last_7_days",
                    "description": "ç›´æ¥æ‰§è¡Œç”¨æˆ·æŸ¥è¯¢"
                }]

            logger.info(f"\næå–åˆ° {len(initial_instructions)} æ¡åˆæ­¥æŸ¥è¯¢æŒ‡ä»¤:")
            for i, inst in enumerate(initial_instructions, 1):
                logger.info(f"  {i}. {inst.get('task', inst)}")

            # ============ é˜¶æ®µ2: æ‰§è¡Œåˆæ­¥æŸ¥è¯¢ ============
            logger.info("\n" + "=" * 80)
            logger.info("ã€é˜¶æ®µ2ã€‘ä¸‹å±‚æ‰§è¡ŒAgent - æ‰§è¡Œåˆæ­¥æŸ¥è¯¢")
            logger.info("=" * 80)

            initial_results = self._execute_instructions(initial_instructions)

            # æ£€æŸ¥åˆæ­¥æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
            success_count = sum(1 for r in initial_results if r.get("status") == "success")
            logger.info(f"\nåˆæ­¥æŸ¥è¯¢å®Œæˆ: {success_count}/{len(initial_results)} æˆåŠŸ")

            # ============ é˜¶æ®µ3: è¯„ä¼°æ˜¯å¦éœ€è¦ä¸‹é’» ============
            drilldown_results = []
            drilldown_instructions = []

            if enable_progressive_analysis and success_count > 0:
                logger.info("\n" + "=" * 80)
                logger.info("ã€é˜¶æ®µ3ã€‘ä¸Šå±‚åˆ†æAgent - è¯„ä¼°æ˜¯å¦éœ€è¦ä¸‹é’»")
                logger.info("=" * 80)

                decision = self.analyst_agent.evaluate_and_decide_drilldown(
                    user_question=user_input,
                    initial_results=initial_results
                )

                logger.info(f"\n[ä¸‹é’»å†³ç­–] {'éœ€è¦ä¸‹é’»' if decision['need_drilldown'] else 'ä¸éœ€è¦ä¸‹é’»'}")
                logger.info(f"[å†³ç­–ç†ç”±] {decision['reasoning']}")

                # ============ é˜¶æ®µ4: æ‰§è¡Œä¸‹é’»æŸ¥è¯¢ (å¦‚æœéœ€è¦) ============
                if decision["need_drilldown"]:
                    logger.info("\n" + "=" * 80)
                    logger.info("ã€é˜¶æ®µ4ã€‘ç”Ÿæˆå¹¶æ‰§è¡Œä¸‹é’»æŸ¥è¯¢")
                    logger.info("=" * 80)

                    # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
                    context = {
                        "initial_results": self.analyst_agent._extract_results_summary(initial_results),
                        "suggested_dimensions": decision["suggested_dimensions"]
                    }

                    # ç”Ÿæˆä¸‹é’»æŒ‡ä»¤
                    drilldown_analysis = self.analyst_agent.analyze(
                        user_question=user_input,
                        context=context,
                        stage="drilldown"
                    )
                    drilldown_plan = drilldown_analysis.get("analysis_plan", "")
                    drilldown_instructions = self._parse_instructions(drilldown_plan)

                    if drilldown_instructions:
                        logger.info(f"\næå–åˆ° {len(drilldown_instructions)} æ¡ä¸‹é’»æŒ‡ä»¤:")
                        for i, inst in enumerate(drilldown_instructions, 1):
                            logger.info(f"  {i}. {inst.get('task', inst)}")

                        # æ‰§è¡Œä¸‹é’»æŸ¥è¯¢
                        drilldown_results = self._execute_instructions(drilldown_instructions)

                        drilldown_success = sum(1 for r in drilldown_results if r.get("status") == "success")
                        logger.info(f"\nä¸‹é’»æŸ¥è¯¢å®Œæˆ: {drilldown_success}/{len(drilldown_results)} æˆåŠŸ")
                    else:
                        logger.info("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ä¸‹é’»æŒ‡ä»¤")
                else:
                    logger.info("\nåˆæ­¥ç»“æœå·²è¶³å¤Ÿï¼Œè·³è¿‡ä¸‹é’»åˆ†æ")

            # ============ é˜¶æ®µ5: ç»¼åˆåˆ†æ ============
            logger.info("\n" + "=" * 80)
            logger.info("ã€é˜¶æ®µ5ã€‘ä¸Šå±‚åˆ†æAgent - ç»¼åˆæ‰€æœ‰ç»“æœ")
            logger.info("=" * 80)

            # åˆå¹¶æ‰€æœ‰ç»“æœ
            all_results = initial_results + drilldown_results
            all_instructions = initial_instructions + drilldown_instructions

            # å¦‚æœåªæœ‰ä¸€ä¸ªåˆæ­¥æŸ¥è¯¢ä¸”æˆåŠŸï¼Œä¸”ä¸éœ€è¦ä¸‹é’»ï¼Œè½¬æ¢ä¸ºMarkdownæ ¼å¼è¿”å›
            if len(all_results) == 1 and all_results[0].get("status") == "success" and not drilldown_results:
                logger.info("å•ä¸€æŸ¥è¯¢æˆåŠŸä¸”ä¸éœ€è¦ä¸‹é’»ï¼Œè½¬æ¢ä¸ºMarkdownæ ¼å¼")
                final_result = self._format_single_result_to_markdown(
                    user_question=user_input,
                    result=all_results[0]
                )
                logger.info("=" * 80)
                logger.info("[Orchestrator V2] æŸ¥è¯¢å¤„ç†å®Œæˆ")
                logger.info("=" * 80)
                return final_result

            # éœ€è¦ç»¼åˆåˆ†æ
            logger.info("å¼€å§‹ç»¼åˆå¤šä¸ªæŸ¥è¯¢ç»“æœ...")
            synthesis_report = self.analyst_agent.synthesize_results(
                instructions=all_instructions,
                results=all_results
            )

            # ============ è¿”å›æœ€ç»ˆç»“æœ ============
            logger.info("=" * 80)
            logger.info("[Orchestrator V2] æŸ¥è¯¢å¤„ç†å®Œæˆ")
            logger.info("=" * 80)

            # æ„å»ºæœ€ç»ˆè¾“å‡º
            return self._format_final_output(
                analysis_plan=analysis_plan,
                initial_results=initial_results,
                drilldown_results=drilldown_results,
                synthesis_report=synthesis_report
            )

        except Exception as e:
            error_msg = f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}"
            logger.error("=" * 80)
            logger.error(f"[Orchestrator V2] {error_msg}")
            logger.error("=" * 80)
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return error_msg

    def _generate_instruction_hash(self, instruction: str) -> str:
        """
        ç”ŸæˆæŒ‡ä»¤çš„å”¯ä¸€æ ‡è¯†hash

        ç”¨äºæŸ¥è¯¢å»é‡ï¼šç›¸åŒçš„æŒ‡ä»¤ä¼šç”Ÿæˆç›¸åŒçš„hash

        Args:
            instruction: æŒ‡ä»¤å­—ç¬¦ä¸²

        Returns:
            32ä½çš„MD5 hashå­—ç¬¦ä¸²
        """
        import hashlib

        # æ ‡å‡†åŒ–æŒ‡ä»¤æ–‡æœ¬ï¼ˆå»é™¤ç©ºæ ¼ã€è½¬å°å†™ï¼‰ä»¥ä¾¿æ›´å¥½åœ°åŒ¹é…
        normalized = instruction.strip().lower()

        # ç”ŸæˆMD5 hash
        hash_obj = hashlib.md5(normalized.encode('utf-8'))
        return hash_obj.hexdigest()

    def _parse_instructions(self, analysis_plan: str) -> list:
        """
        ä»åˆ†æè®¡åˆ’ä¸­è§£ææŒ‡ä»¤

        Args:
            analysis_plan: åˆ†æè®¡åˆ’æ–‡æœ¬

        Returns:
            æŒ‡ä»¤åˆ—è¡¨
        """
        instructions = []

        try:
            # å°è¯•ä»JSONä»£ç å—ä¸­æå–
            json_pattern = r'```(?:json|python)?\s*(\{.*?\})\s*```'
            matches = re.finditer(json_pattern, analysis_plan, re.DOTALL)

            for match in matches:
                try:
                    json_str = match.group(1)
                    # ç§»é™¤Pythonå˜é‡èµ‹å€¼
                    json_str = re.sub(r'^\s*\w+\s*=\s*', '', json_str)
                    instruction = json.loads(json_str)
                    instructions.append(instruction)
                except json.JSONDecodeError:
                    continue

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
            if not instructions:
                # æŸ¥æ‰¾"æŸ¥è¯¢"ã€"åˆ†æ"ç­‰å…³é”®è¯å¼€å¤´çš„è¡Œ
                lines = analysis_plan.split('\n')
                for line in lines:
                    line = line.strip()
                    if any(keyword in line for keyword in ["æŸ¥è¯¢", "åˆ†æ", "ç»Ÿè®¡", "è®¡ç®—"]):
                        if len(line) > 10 and not line.startswith('#'):
                            instructions.append({"task": line})

        except Exception as e:
            logger.error(f"è§£ææŒ‡ä»¤å¤±è´¥: {e}")

        return instructions

    def _extract_plan_summary(self, analysis_plan: str) -> str:
        """
        ä»åˆ†æè®¡åˆ’ä¸­æå–æ‘˜è¦

        Args:
            analysis_plan: åˆ†æè®¡åˆ’æ–‡æœ¬

        Returns:
            è®¡åˆ’æ‘˜è¦
        """
        # æå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        lines = analysis_plan.split('\n')
        summary_lines = []

        for line in lines:
            line = line.strip()
            # è·³è¿‡ä»£ç å—
            if line.startswith('```') or line.startswith('{') or line.startswith('['):
                continue
            if line:
                summary_lines.append(line)
                if len(summary_lines) >= 5:  # åªè¦å‰5è¡Œéç©ºè¡Œ
                    break

        return '\n'.join(summary_lines) if summary_lines else "è‡ªåŠ¨åˆ†æ"

    def _execute_instructions(self, instructions: list) -> list:
        """
        æ‰§è¡Œä¸€ç»„æŒ‡ä»¤ï¼Œæ”¯æŒæŸ¥è¯¢å»é‡å’Œç¼“å­˜

        Args:
            instructions: æŒ‡ä»¤åˆ—è¡¨

        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        execution_results = []
        query_cache = {}  # æŸ¥è¯¢ç¼“å­˜: {æŒ‡ä»¤hash: ç»“æœ}
        deduplicated_count = 0

        for i, instruction in enumerate(instructions, 1):
            logger.info(f"\n--- æ‰§è¡ŒæŒ‡ä»¤ {i}/{len(instructions)} ---")

            # å°†æŒ‡ä»¤è½¬æ¢ä¸ºå­—ç¬¦ä¸²(å¦‚æœæ˜¯å­—å…¸)
            if isinstance(instruction, dict):
                instruction_str = instruction.get("task", json.dumps(instruction, ensure_ascii=False))
            else:
                instruction_str = str(instruction)

            # ç”ŸæˆæŒ‡ä»¤çš„å”¯ä¸€æ ‡è¯†
            instruction_hash = self._generate_instruction_hash(instruction_str)

            # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡ç›¸åŒçš„æŒ‡ä»¤
            if instruction_hash in query_cache:
                logger.info(f"âš¡ æ£€æµ‹åˆ°é‡å¤æŒ‡ä»¤ï¼Œä½¿ç”¨ç¼“å­˜ç»“æœ (hash: {instruction_hash[:8]}...)")
                result = query_cache[instruction_hash].copy()
                result["from_cache"] = True  # æ ‡è®°ä¸ºç¼“å­˜ç»“æœ
                deduplicated_count += 1
            else:
                # è°ƒç”¨ä¸‹å±‚Agentæ‰§è¡Œ
                logger.info(f"ğŸ” æ‰§è¡Œæ–°æŒ‡ä»¤ (hash: {instruction_hash[:8]}...)")
                result = self.engineer_agent.execute_instruction(instruction_str)
                result["query_hash"] = instruction_hash  # æ·»åŠ æŸ¥è¯¢æ ‡è¯†
                result["instruction"] = instruction_str  # è®°å½•åŸå§‹æŒ‡ä»¤

                # ç¼“å­˜æˆåŠŸçš„æŸ¥è¯¢ç»“æœ
                if result.get("status") == "success":
                    query_cache[instruction_hash] = result.copy()

            execution_results.append(result)

            # è®°å½•æ‰§è¡ŒçŠ¶æ€
            status = result.get("status")
            if status == "success":
                cache_info = " (ç¼“å­˜)" if result.get("from_cache") else ""
                logger.info(f"âœ… æŒ‡ä»¤ {i} æ‰§è¡ŒæˆåŠŸ{cache_info}")
            elif status == "partial":
                logger.warning(f"âš ï¸  æŒ‡ä»¤ {i} éƒ¨åˆ†å®Œæˆ: {result.get('result', result.get('error'))}")
            else:
                logger.error(f"âŒ æŒ‡ä»¤ {i} æ‰§è¡Œå¤±è´¥: {result.get('error')}")

        # è®°å½•å»é‡ç»Ÿè®¡
        if deduplicated_count > 0:
            logger.info(f"\nğŸ’¾ æŸ¥è¯¢å»é‡: é¿å…äº† {deduplicated_count} æ¬¡é‡å¤æ‰§è¡Œ")

        return execution_results

    def _format_single_result_to_markdown(
        self,
        user_question: str,
        result: Dict[str, Any]
    ) -> str:
        """
        å°†å•ä¸ªæŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºMarkdownæ ¼å¼

        Args:
            user_question: ç”¨æˆ·åŸå§‹é—®é¢˜
            result: æŸ¥è¯¢ç»“æœ (åŒ…å«JSONæ ¼å¼çš„resultå­—æ®µ)

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        import json

        # è§£æresultå­—æ®µä¸­çš„JSONæ•°æ®
        result_data = result.get("result", "")

        try:
            # å°è¯•è§£æJSON
            if isinstance(result_data, str):
                data = json.loads(result_data)
            else:
                data = result_data

            # æ„å»ºMarkdownæŠ¥å‘Š
            lines = []
            lines.append("# æ•°æ®åˆ†æç»“æœ")
            lines.append("")
            lines.append(f"**æŸ¥è¯¢é—®é¢˜:** {user_question}")
            lines.append("")
            lines.append("---")
            lines.append("")

            # æ·»åŠ æ ¸å¿ƒæŒ‡æ ‡
            lines.append("## æ ¸å¿ƒæŒ‡æ ‡")
            lines.append("")

            summary = data.get("summary", {})
            if summary:
                # æ—¶é—´èŒƒå›´
                if "date_range" in summary:
                    date_range = summary["date_range"]
                    lines.append(f"- **æŸ¥è¯¢æ—¶é—´èŒƒå›´:** {date_range[0]} è‡³ {date_range[1]}")

                # è®¢å•æ€»æ•°
                if "total_orders" in summary:
                    lines.append(f"- **è®¢å•æ€»æ•°:** {summary['total_orders']:,}")

                # æ¸ é“æ•°é‡
                if "total_channels" in summary:
                    lines.append(f"- **æ¸ é“æ•°é‡:** {summary['total_channels']}")

                # Topæ¸ é“
                if "top_channel" in summary:
                    top = summary["top_channel"]
                    lines.append(f"- **æœ€å¤§æ¸ é“:** {top['name']} (è®¢å•æ•°: {top['orders']:,}, GMV: ${top['gmv']:,.2f})")

                lines.append("")

            # æ·»åŠ æ•°æ®é¢„è§ˆ
            lines.append("## æ•°æ®é¢„è§ˆ")
            lines.append("")

            preview = data.get("preview", "")
            if preview:
                # è§£æé¢„è§ˆæ–‡æœ¬å¹¶è½¬æ¢ä¸ºè¡¨æ ¼
                preview_lines = preview.strip().split('\n')

                # æŸ¥æ‰¾è¡¨æ ¼éƒ¨åˆ†
                table_start = -1
                for i, line in enumerate(preview_lines):
                    if 'æ¸ é“' in line and 'è®¢å•æ•°é‡' in line:
                        table_start = i
                        break

                if table_start >= 0:
                    # è¾“å‡ºæ ‡é¢˜
                    lines.append("| æ’å | æ¸ é“ | è®¢å•æ•°é‡ | GMV |")
                    lines.append("|------|------|----------|-----|")

                    # è¾“å‡ºæ•°æ®è¡Œ
                    data_lines = preview_lines[table_start + 2:]  # è·³è¿‡æ ‡é¢˜å’Œåˆ†éš”çº¿
                    for line in data_lines:
                        if line.strip() and not line.startswith('-') and not line.startswith('...'):
                            # è§£ææ¯ä¸€è¡Œ: "1. facebook      57,385    $4,084,836.73"
                            parts = line.strip().split()
                            if len(parts) >= 3:
                                rank = parts[0].rstrip('.')
                                channel = parts[1]
                                orders = parts[2] if len(parts) > 2 else '-'
                                gmv = parts[3] if len(parts) > 3 else '-'
                                lines.append(f"| {rank} | {channel} | {orders} | {gmv} |")
                else:
                    # å¦‚æœæ— æ³•è§£æä¸ºè¡¨æ ¼ï¼Œç›´æ¥è¾“å‡ºåŸå§‹é¢„è§ˆ
                    lines.append("```")
                    lines.append(preview)
                    lines.append("```")

            lines.append("")

            # æ·»åŠ å®Œæ•´æ•°æ®æ–‡ä»¶ä¿¡æ¯
            lines.append("## å®Œæ•´æ•°æ®")
            lines.append("")
            lines.append(f"- **CSVæ–‡ä»¶è·¯å¾„:** `{data.get('csv_path', 'N/A')}`")
            lines.append(f"- **æ•°æ®è¡Œæ•°:** {data.get('rows', 'N/A')}")
            lines.append(f"- **æ•°æ®åˆ—:** {', '.join(data.get('columns', []))}")
            lines.append("")

            # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
            if "query_info" in summary:
                query_info = summary["query_info"]
                lines.append("## æŸ¥è¯¢è¯¦æƒ…")
                lines.append("")
                lines.append(f"- **äº‹ä»¶ç±»å‹:** {query_info.get('event', 'N/A')}")
                lines.append(f"- **å›½å®¶ç­›é€‰:** {query_info.get('country_filter', 'N/A')}")
                lines.append(f"- **çˆ¬è™«è¿‡æ»¤:** {query_info.get('spider_filter', 'N/A')}")
                lines.append("")

            lines.append("---")
            lines.append("")
            lines.append(f"*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

            return "\n".join(lines)

        except json.JSONDecodeError as e:
            logger.warning(f"æ— æ³•è§£æJSONç»“æœ: {e}")
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
            return f"# æŸ¥è¯¢ç»“æœ\n\n```json\n{result_data}\n```"
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç»“æœå¤±è´¥: {e}", exc_info=True)
            return f"# æŸ¥è¯¢ç»“æœ\n\næ ¼å¼åŒ–å¤±è´¥: {str(e)}\n\n```\n{result_data}\n```"

    def _format_final_output(
        self,
        analysis_plan: str,
        initial_results: list,
        drilldown_results: list,
        synthesis_report: str
    ) -> str:
        """
        æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡ºæŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰

        Args:
            analysis_plan: åˆ†æè®¡åˆ’
            initial_results: åˆæ­¥æŸ¥è¯¢ç»“æœ
            drilldown_results: ä¸‹é’»æŸ¥è¯¢ç»“æœ
            synthesis_report: ç»¼åˆåˆ†ææŠ¥å‘Šï¼ˆå·²ç»æ˜¯Markdownæ ¼å¼ï¼‰

        Returns:
            Markdownæ ¼å¼çš„å®Œæ•´æŠ¥å‘Š
        """
        # å¦‚æœç»¼åˆæŠ¥å‘Šå·²ç»æ˜¯å®Œæ•´çš„Markdownæ ¼å¼ï¼Œç›´æ¥è¿”å›
        # ï¼ˆå› ä¸ºanalyst_agentçš„synthesize_resultså·²ç»ç”Ÿæˆäº†å®Œæ•´çš„MarkdownæŠ¥å‘Šï¼‰
        if synthesis_report.strip().startswith("#"):
            return synthesis_report

        # å¦‚æœä¸æ˜¯Markdownæ ¼å¼ï¼Œä½¿ç”¨ä¼ ç»Ÿæ ¼å¼ä½œä¸ºåå¤‡
        output_lines = []
        output_lines.append("# ç¥ç­–æ•°æ®åˆ†ææŠ¥å‘Š")
        output_lines.append("")
        output_lines.append("> **åˆ†ææ–¹æ³•:** æ¸è¿›å¼åŒå±‚æ™ºèƒ½åˆ†æ")
        output_lines.append("")
        output_lines.append("---")
        output_lines.append("")

        # æ·»åŠ åˆ†ææ–¹æ³•æ‘˜è¦
        output_lines.append("## åˆ†ææ–¹æ³•")
        output_lines.append("")
        output_lines.append(self._extract_plan_summary(analysis_plan))
        output_lines.append("")

        # æ·»åŠ åˆæ­¥æŸ¥è¯¢ç»“æœ
        output_lines.append("## åˆæ­¥æŸ¥è¯¢ç»“æœ")
        output_lines.append("")
        for i, result in enumerate(initial_results, 1):
            if result.get("status") == "success":
                output_lines.append(f"### æŸ¥è¯¢ {i}")
                output_lines.append("")
                output_lines.append(str(result.get("result", "")))
                output_lines.append("")
            else:
                output_lines.append(f"### æŸ¥è¯¢ {i} âŒ")
                output_lines.append("")
                output_lines.append(f"**é”™è¯¯:** {result.get('error')}")
                output_lines.append("")

        # å¦‚æœæœ‰ä¸‹é’»æŸ¥è¯¢ï¼Œæ·»åŠ ä¸‹é’»ç»“æœ
        if drilldown_results:
            output_lines.append("## æ·±å…¥åˆ†æç»“æœ")
            output_lines.append("")
            for i, result in enumerate(drilldown_results, 1):
                if result.get("status") == "success":
                    output_lines.append(f"### æ·±å…¥æŸ¥è¯¢ {i}")
                    output_lines.append("")
                    output_lines.append(str(result.get("result", "")))
                    output_lines.append("")
                else:
                    output_lines.append(f"### æ·±å…¥æŸ¥è¯¢ {i} âŒ")
                    output_lines.append("")
                    output_lines.append(f"**é”™è¯¯:** {result.get('error')}")
                    output_lines.append("")

        # æ·»åŠ ç»¼åˆåˆ†æ
        output_lines.append("## ä¸šåŠ¡æ´å¯Ÿä¸å»ºè®®")
        output_lines.append("")
        output_lines.append(synthesis_report)
        output_lines.append("")
        output_lines.append("---")

        return "\n".join(output_lines)

    def reset(self):
        """é‡ç½®å¯¹è¯çŠ¶æ€"""
        logger.info("é‡ç½®åŒå±‚AgentçŠ¶æ€")
        # é‡æ–°åˆå§‹åŒ–ä¸¤ä¸ªAgent
        self.analyst_agent = AnalystAgent(
            model_name=self.settings.LITELLM_MODEL,
            api_key=self.settings.LITELLM_API_KEY
        )
        self.engineer_agent = EngineerAgent(
            sensors_client=self.sensors_client,
            model_name=self.settings.LITELLM_MODEL,
            api_key=self.settings.LITELLM_API_KEY
        )

    def close(self):
        """å…³é—­èµ„æº"""
        logger.info("å…³é—­åŒå±‚Agentèµ„æº")
        if self.engineer_agent:
            self.engineer_agent.close()
        if self.sensors_client:
            self.sensors_client.close()


def create_agent_v2(
    analyst_model_name: Optional[str] = None,
    engineer_model_name: Optional[str] = None,
    api_key: Optional[str] = None
) -> SensorsAnalyticsAgentV2:
    """
    å·¥å‚å‡½æ•°: åˆ›å»ºåŒå±‚æ¶æ„çš„ç¥ç­–åˆ†æAgent

    Args:
        analyst_model_name: ä¸Šå±‚Agentæ¨¡å‹åç§°
        engineer_model_name: ä¸‹å±‚Agentæ¨¡å‹åç§°
        api_key: APIå¯†é’¥

    Returns:
        SensorsAnalyticsAgentV2å®ä¾‹
    """
    return SensorsAnalyticsAgentV2(
        analyst_model_name=analyst_model_name,
        engineer_model_name=engineer_model_name,
        api_key=api_key
    )
