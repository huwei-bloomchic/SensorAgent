"""
SQLæŸ¥è¯¢å·¥å…·
ç”¨äºæ‰§è¡Œç¥ç­–SQLæŸ¥è¯¢ï¼Œæ”¯æŒåŸºäºäº‹ä»¶æ–‡æ¡£çš„æ™ºèƒ½æŸ¥è¯¢
"""
import os
from loguru import logger
from src.tools.base_tool import BaseSensorsTool


class SQLQueryTool(BaseSensorsTool):
    """
    SQLæŸ¥è¯¢å·¥å…·

    æ‰§è¡Œç¥ç­–SQLæŸ¥è¯¢ï¼Œå¯ä»¥ç›´æ¥æŸ¥è¯¢äº‹ä»¶è¡¨å’Œç”¨æˆ·è¡¨
    æ”¯æŒå¤æ‚çš„åˆ†æåœºæ™¯ï¼Œå¦‚å¤šäº‹ä»¶å…³è”ã€è‡ªå®šä¹‰è®¡ç®—ç­‰
    """

    name = "sql_query"
    description = """æ‰§è¡Œç¥ç­–SQLæŸ¥è¯¢ã€‚

ä½¿ç”¨æ­¤å·¥å…·å¯ä»¥ï¼š
- æ‰§è¡Œå¤æ‚çš„SQLæŸ¥è¯¢
- å¤šäº‹ä»¶å…³è”åˆ†æ
- è‡ªå®šä¹‰æŒ‡æ ‡è®¡ç®—
- çµæ´»çš„æ•°æ®ç­›é€‰å’Œèšåˆ

å‚æ•°è¯´æ˜ï¼š
- sql: SQLæŸ¥è¯¢è¯­å¥ï¼ˆå¿…å¡«ï¼‰
  å¯ä»¥æŸ¥è¯¢eventsè¡¨ï¼ˆäº‹ä»¶è¡¨ï¼‰å’Œusersè¡¨ï¼ˆç”¨æˆ·è¡¨ï¼‰
- limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰
  ä¸æä¾›æ—¶è¿”å›æ‰€æœ‰ç»“æœ

SQLæŸ¥è¯¢ç¤ºä¾‹ï¼ˆæ‰€æœ‰ç¤ºä¾‹éƒ½åŒ…å«å¿…è¦çš„ä¼˜åŒ–æ¡ä»¶ï¼‰ï¼š

1. æŸ¥è¯¢æœ€è¿‘7å¤©çš„åº”ç”¨å¯åŠ¨æ¬¡æ•°ï¼ˆå«çˆ¬è™«è¿‡æ»¤ï¼‰ï¼š
   SELECT COUNT(*) as total_count, COUNT(DISTINCT distinct_id) as user_count
   FROM events
   WHERE event = '$AppStart'
   AND date BETWEEN '2024-12-02' AND '2024-12-09'
   AND is_spider_user = 'æ­£å¸¸ç”¨æˆ·'

2. æŒ‰æ—¥æœŸåˆ†ç»„æŸ¥è¯¢å•†å“ç‚¹å‡»ï¼ˆå«çˆ¬è™«è¿‡æ»¤ï¼‰ï¼š
   SELECT
     date,
     COUNT(*) as clicks,
     COUNT(DISTINCT distinct_id) as users
   FROM events
   WHERE event = 'ProductClick'
   AND date BETWEEN '2024-12-02' AND '2024-12-09'
   AND is_spider_user = 'æ­£å¸¸ç”¨æˆ·'
   GROUP BY date
   ORDER BY date

3. æŸ¥è¯¢è´­ä¹°è½¬åŒ–æ¼æ–—ï¼ˆå«çˆ¬è™«è¿‡æ»¤ï¼‰ï¼š
   SELECT
     COUNT(DISTINCT CASE WHEN event = 'ProductClick' THEN distinct_id END) as click_users,
     COUNT(DISTINCT CASE WHEN event = 'AddToCartClick' THEN distinct_id END) as cart_users,
     COUNT(DISTINCT CASE WHEN event = 'PurchaseSuccess' THEN distinct_id END) as purchase_users
   FROM events
   WHERE date BETWEEN '2024-12-02' AND '2024-12-09'
   AND is_spider_user = 'æ­£å¸¸ç”¨æˆ·'
   AND event IN ('ProductClick', 'AddToCartClick', 'PurchaseSuccess')

é‡è¦æç¤ºï¼š
- äº‹ä»¶åä½¿ç”¨ event å­—æ®µï¼Œä¸æ˜¯ event_name
- å¸¸ç”¨äº‹ä»¶åå‚è€ƒï¼š$AppStart, ProductClick, AddToCartClick, PurchaseSuccess ç­‰
- äº‹ä»¶å±æ€§é€šè¿‡ properties è®¿é—®ï¼Œå¦‚: properties['product_spu']
- æ—¥æœŸå­—æ®µä½¿ç”¨ dateï¼Œæ—¶é—´æˆ³ä½¿ç”¨ time
- ç”¨æˆ·IDä½¿ç”¨ distinct_id å­—æ®µ

SQL æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
âš ï¸ ä¸ºé¿å…æŸ¥è¯¢è¶…æ—¶å’Œèµ„æºæµªè´¹ï¼Œç¼–å†™ SQL æ—¶å¿…é¡»ï¼š
1. ã€å¿…é¡»ã€‘æ·»åŠ æ—¶é—´èŒƒå›´è¿‡æ»¤ï¼šWHERE date BETWEEN 'YYYY-MM-DD' AND 'YYYY-MM-DD'
   - ä¸æŒ‡å®šæ—¶é—´èŒƒå›´ä¼šå¯¼è‡´å…¨è¡¨æ‰«æï¼ŒæŸ¥è¯¢ææ…¢
   - å»ºè®®æŸ¥è¯¢æœ€è¿‘ 7-30 å¤©çš„æ•°æ®
2. ã€å¿…é¡»ã€‘æŒ‡å®šäº‹ä»¶åï¼šWHERE event = 'å…·ä½“äº‹ä»¶å' æˆ–è€… event in ('','')
   - é¿å…æŸ¥è¯¢æ‰€æœ‰äº‹ä»¶ï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡
3. ã€å¼ºçƒˆå»ºè®®ã€‘è¿‡æ»¤çˆ¬è™«æ•°æ®ï¼šAND is_spider_user = 'æ­£å¸¸ç”¨æˆ·'
   - Web ç«¯æœ‰å¤§é‡çˆ¬è™«æ•°æ®ï¼Œä¼šä¸¥é‡å½±å“ç»Ÿè®¡å‡†ç¡®æ€§
   - is_spider_user å€¼ï¼š'æ­£å¸¸ç”¨æˆ·' æˆ– 'çˆ¬è™«ç”¨æˆ·'
4. ä½¿ç”¨ LIMIT é™åˆ¶è¿”å›ç»“æœæ•°é‡ï¼Œé¿å…è¿”å›è¿‡å¤šæ•°æ®
"""

    inputs = {
        "sql": {
            "type": "string",
            "description": "SQLæŸ¥è¯¢è¯­å¥"
        },
        "limit": {
            "type": "integer",
            "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼Œé»˜è®¤1000000000ï¼ˆå»ºè®®ä¿æŒé»˜è®¤å€¼ï¼‰",
            "nullable": True
        }
    }

    output_type = "string"

    def __init__(self, sensors_client):
        super().__init__(sensors_client)
        self.events_doc = self._load_events_doc()
        logger.info("SQLQueryTool åˆå§‹åŒ–å®Œæˆ")

    def _load_events_doc(self) -> str:
        """åŠ è½½äº‹ä»¶æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡"""
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(current_dir))
            events_doc_path = os.path.join(project_root, "events.md")

            if os.path.exists(events_doc_path):
                with open(events_doc_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    logger.info(f"æˆåŠŸåŠ è½½äº‹ä»¶æ–‡æ¡£: {len(content)} å­—ç¬¦")
                    return content
            else:
                logger.warning(f"äº‹ä»¶æ–‡æ¡£ä¸å­˜åœ¨: {events_doc_path}")
                return ""
        except Exception as e:
            logger.error(f"åŠ è½½äº‹ä»¶æ–‡æ¡£å¤±è´¥: {str(e)}")
            return ""

    def get_events_context(self) -> str:
        """è·å–äº‹ä»¶æ–‡æ¡£ä¸Šä¸‹æ–‡ï¼Œä¾›AIå‚è€ƒ"""
        return self.events_doc

    def validate_params(self, **kwargs) -> bool:
        """éªŒè¯å‚æ•°"""
        if "sql" not in kwargs or not kwargs["sql"]:
            raise ValueError("sql å‚æ•°æ˜¯å¿…å¡«çš„")

        sql = kwargs["sql"].strip()
        if not sql:
            raise ValueError("SQLè¯­å¥ä¸èƒ½ä¸ºç©º")

        sql_upper = sql.upper()

        # åŸºæœ¬çš„SQLå®‰å…¨æ£€æŸ¥
        dangerous_keywords = ["DROP", "DELETE", "TRUNCATE", "ALTER", "CREATE", "INSERT", "UPDATE"]
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                raise ValueError(f"ä¸å…è®¸æ‰§è¡Œ {keyword} æ“ä½œï¼Œä»…æ”¯æŒ SELECT æŸ¥è¯¢")

        # æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥ï¼ˆè­¦å‘Šä½†ä¸é˜»æ­¢ï¼‰
        warnings = []

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´èŒƒå›´è¿‡æ»¤
        if "DATE" not in sql_upper and "`DATE`" not in sql_upper:
            warnings.append("âš ï¸ å»ºè®®æ·»åŠ æ—¶é—´èŒƒå›´è¿‡æ»¤ (date BETWEEN ... AND ...) ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½")

        # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº‹ä»¶å
        if "EVENT" not in sql_upper and "`EVENT`" not in sql_upper:
            warnings.append("âš ï¸ å»ºè®®æŒ‡å®šäº‹ä»¶å (event = '...') ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡")

        # æ£€æŸ¥æ˜¯å¦è¿‡æ»¤çˆ¬è™«
        if "IS_SPIDER_USER" not in sql_upper and "`IS_SPIDER_USER`" not in sql_upper:
            warnings.append("âš ï¸ å»ºè®®è¿‡æ»¤çˆ¬è™«æ•°æ® (is_spider_user = 'æ­£å¸¸ç”¨æˆ·') ä»¥ç¡®ä¿æ•°æ®å‡†ç¡®æ€§")

        # å¦‚æœæœ‰è­¦å‘Šï¼Œè®°å½•åˆ°æ—¥å¿—
        if warnings:
            logger.warning("SQLæŸ¥è¯¢ä¼˜åŒ–å»ºè®®ï¼š")
            for warning in warnings:
                logger.warning(f"  {warning}")

        return True

    def forward(self, sql: str, limit: int = 1000000000) -> str:
        """
        æ‰§è¡ŒSQLæŸ¥è¯¢

        Args:
            sql: SQLæŸ¥è¯¢è¯­å¥
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼Œé»˜è®¤1000000000ï¼ˆç¥ç­–APIè¦æ±‚å¿…å¡«ï¼‰

        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        logger.info(f"æ‰§è¡ŒSQLæŸ¥è¯¢:\n{sql}")

        try:
            # æ‰§è¡ŒSQLæŸ¥è¯¢ï¼ˆlimitæ˜¯å¿…å¡«å‚æ•°ï¼‰
            result = self.client.execute_sql(sql, limit=limit)

            # æ ¼å¼åŒ–ç»“æœ
            return self._format_sql_result(result, sql)

        except Exception as e:
            logger.error(f"SQLæŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
            logger.error(f"å¤±è´¥çš„SQL:\n{sql}")
            if limit is not None:
                logger.error(f"é™åˆ¶æ¡æ•°: {limit}")
            return self.handle_error(e)

    def _format_sql_result(self, data: dict, sql: str) -> str:
        """
        æ ¼å¼åŒ–SQLæŸ¥è¯¢ç»“æœ

        Args:
            data: APIè¿”å›çš„åŸå§‹æ•°æ®
            sql: æ‰§è¡Œçš„SQLè¯­å¥

        Returns:
            æ ¼å¼åŒ–åçš„ç»“æœå­—ç¬¦ä¸²ï¼ˆåŒ…å«å¯è¯»è¡¨æ ¼å’Œç»“æ„åŒ–æ•°æ®ï¼‰
        """
        lines = ["=" * 60]
        lines.append("SQLæŸ¥è¯¢ç»“æœ")
        lines.append("=" * 60)
        lines.append("")

        # æ˜¾ç¤ºæ‰§è¡Œçš„SQLï¼ˆæˆªæ–­è¿‡é•¿çš„SQLï¼‰
        sql_display = sql if len(sql) <= 200 else sql[:200] + "..."
        lines.append(f"æ‰§è¡Œçš„SQL:")
        lines.append(f"  {sql_display}")
        lines.append("")

        # å¦‚æœAPIè¿”å›äº†é”™è¯¯
        if "error" in data:
            lines.append(f"âŒ æŸ¥è¯¢å¤±è´¥: {data['error']}")
            return "\n".join(lines)

        # æå–æŸ¥è¯¢ç»“æœ
        if "rows" in data:
            rows = data["rows"]
            columns = data.get("columns", [])

            if not rows:
                lines.append("æŸ¥è¯¢ç»“æœä¸ºç©º")
            else:
                lines.append(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: {len(rows)} è¡Œ")
                lines.append("")

                # å¦‚æœæœ‰åˆ—åï¼Œæ˜¾ç¤ºåˆ—å
                if columns:
                    header = " | ".join(str(col) for col in columns)
                    lines.append(header)
                    lines.append("-" * len(header))

                # æ˜¾ç¤ºæ•°æ®è¡Œï¼ˆé™åˆ¶æ˜¾ç¤ºå‰100è¡Œï¼‰
                max_display_rows = 100
                for i, row in enumerate(rows[:max_display_rows]):
                    if isinstance(row, dict):
                        row_str = " | ".join(f"{k}: {v}" for k, v in row.items())
                    elif isinstance(row, (list, tuple)):
                        row_str = " | ".join(str(v) for v in row)
                    else:
                        row_str = str(row)
                    lines.append(row_str)

                if len(rows) > max_display_rows:
                    lines.append("")
                    lines.append(f"... è¿˜æœ‰ {len(rows) - max_display_rows} è¡Œæœªæ˜¾ç¤º")

        elif "data" in data:
            # å…¶ä»–æ ¼å¼çš„æ•°æ®
            lines.append("æŸ¥è¯¢ç»“æœ:")
            lines.append(self.format_result(data["data"]))
        else:
            # æœªçŸ¥æ ¼å¼
            lines.append("åŸå§‹ç»“æœ:")
            lines.append(self.format_result(data))

        lines.append("")
        lines.append("=" * 60)

        # ã€æ–°å¢ã€‘æ·»åŠ ç»“æ„åŒ–æ•°æ®ä¾›åˆ†æå·¥å…·ä½¿ç”¨
        # åªæœ‰å½“æŸ¥è¯¢æˆåŠŸå¹¶æœ‰rowsæ•°æ®æ—¶æ‰æ·»åŠ 
        if "rows" in data and data["rows"]:
            import json

            structured_data = {
                "columns": data.get("columns", []),
                "rows": data["rows"],
                "row_count": len(data["rows"])
            }

            # æ·»åŠ å…ƒæ•°æ®ï¼ˆå¦‚æœå¯ä»¥æ¨æ–­ï¼‰
            metadata = {}

            # å°è¯•æ¨æ–­æ—¥æœŸèŒƒå›´ï¼ˆå¦‚æœæœ‰dateåˆ—ï¼‰
            if "columns" in data and "date" in data["columns"]:
                try:
                    date_idx = data["columns"].index("date")
                    dates = [row[date_idx] for row in data["rows"] if len(row) > date_idx]
                    if dates:
                        metadata["date_range"] = [min(dates), max(dates)]
                except:
                    pass

            if metadata:
                structured_data["metadata"] = metadata

            lines.append("")
            lines.append("<structured_data>")
            lines.append(json.dumps(structured_data, ensure_ascii=False, indent=2))
            lines.append("</structured_data>")

        return "\n".join(lines)
